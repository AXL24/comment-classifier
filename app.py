import streamlit as st
import pandas as pd
import plotly.graph_objects as go
from datetime import datetime
from utils import load_models, predict_toxic

# Page config
st.set_page_config(
    page_title="Ph√°t hi·ªán B√¨nh lu·∫≠n Toxic",
    page_icon="üõ°Ô∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        text-align: center;
        color: #1E88E5;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.2rem;
        text-align: center;
        color: #666;
        margin-bottom: 2rem;
    }
    .toxic-box {
        background-color: #FFEBEE;
        border-left: 5px solid #F44336;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
    .normal-box {
        background-color: #E8F5E9;
        border-left: 5px solid #4CAF50;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1.5rem;
        border-radius: 10px;
        text-align: center;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .stButton>button {
        width: 100%;
        background-color: #1E88E5;
        color: white;
        font-weight: bold;
        padding: 0.75rem;
        font-size: 1.1rem;
    }
</style>
""", unsafe_allow_html=True)

# Initialize session state
if 'history' not in st.session_state:
    st.session_state.history = []

# Load models
@st.cache_resource
def load_model_cache():
    """Load models with caching"""
    try:
        vectorizer, model = load_models()
        return vectorizer, model, None
    except Exception as e:
        return None, None, str(e)

vectorizer, model, error = load_model_cache()

# Header
st.markdown('<div class="main-header">üõ°Ô∏è H·ªá th·ªëng Ph√°t hi·ªán B√¨nh lu·∫≠n Toxic</div>', unsafe_allow_html=True)
st.markdown('<div class="sub-header">Ph√¢n t√≠ch n·ªôi dung tin nh·∫Øn v√† ƒë√°nh gi√° m·ª©c ƒë·ªô ti√™u c·ª±c</div>', unsafe_allow_html=True)

# Check if models loaded successfully
if error:
    st.error(f"‚ùå L·ªói khi t·∫£i model: {error}")
    st.info("Vui l√≤ng ƒë·∫£m b·∫£o c√°c file model ƒë√£ ƒë∆∞·ª£c ƒë·∫∑t trong th∆∞ m·ª•c 'models/'")
    st.stop()

# Sidebar
with st.sidebar:
    st.header("‚öôÔ∏è C√†i ƒë·∫∑t")
    
    # Mode selection
    mode = st.radio(
        "Ch·∫ø ƒë·ªô s·ª≠ d·ª•ng:",
        ["Ph√¢n t√≠ch ƒë∆°n", "Ph√¢n t√≠ch h√†ng lo·∫°t", "L·ªãch s·ª≠"]
    )
    
    st.markdown("---")
    
    # Information
    st.subheader("‚ÑπÔ∏è Th√¥ng tin")
    st.info("""
    **Model:** XGBoost Classifier
    
    **Lo·∫°i Toxic:**
    - Ng√¥n t·ª´ th√¥ t·ª•c
    - X√∫c ph·∫°m, s·ªâ nh·ª•c
    - K·ª≥ th·ªã, ph√¢n bi·ªát ƒë·ªëi x·ª≠
    - ƒêe d·ªça, qu·∫•y r·ªëi
    
    **M·ª©c ƒë·ªô tin c·∫≠y:**
    - üü¢ R·∫•t Cao: > 95%
    - üî¥ Cao: 85-95%
    - üü† Trung B√¨nh: 70-85%
    - üü° Th·∫•p: 50-70%
    - ‚ö™ R·∫•t Th·∫•p: < 50%
    """)
    
    st.markdown("---")
    st.caption("Ph√°t tri·ªÉn b·ªüi [T√™n c·ªßa b·∫°n]")
    st.caption(f"C·∫≠p nh·∫≠t: {datetime.now().strftime('%d/%m/%Y')}")

# Main content
if mode == "Ph√¢n t√≠ch ƒë∆°n":
    st.header("üìù Ph√¢n t√≠ch Tin nh·∫Øn ƒê∆°n")
    
    # Input
    col1, col2 = st.columns([3, 1])
    
    with col1:
        user_input = st.text_area(
            "Nh·∫≠p n·ªôi dung tin nh·∫Øn c·∫ßn ph√¢n t√≠ch:",
            height=150,
            placeholder="V√≠ d·ª•: Ch√†o b·∫°n, h√¥m nay th·∫ø n√†o?"
        )
    
    with col2:
        st.write("")
        st.write("")
        analyze_btn = st.button("üîç Ph√¢n t√≠ch", use_container_width=True)
        clear_btn = st.button("üóëÔ∏è X√≥a", use_container_width=True)
    
    if clear_btn:
        st.rerun()
    
    if analyze_btn:
        if user_input:
            with st.spinner("ƒêang ph√¢n t√≠ch..."):
                # Predict
                result = predict_toxic(user_input, vectorizer, model)
                
                if 'error' in result and result['error']:
                    st.error(result['error'])
                else:
                    # Save to history
                    st.session_state.history.append({
                        'timestamp': datetime.now(),
                        'text': user_input[:100] + '...' if len(user_input) > 100 else user_input,
                        'is_toxic': result['is_toxic'],
                        'confidence': result['confidence']
                    })
                    
                    # Display results
                    st.markdown("---")
                    
                    # Main result
                    if result['is_toxic']:
                        st.markdown(f"""
                        <div class="toxic-box">
                            <h2>üî¥ TOXIC - N·ªôi dung Ti√™u c·ª±c</h2>
                            <p style="font-size: 1.1rem;">Tin nh·∫Øn n√†y c√≥ kh·∫£ nƒÉng ch·ª©a n·ªôi dung ti√™u c·ª±c, x√∫c ph·∫°m ho·∫∑c kh√¥ng ph√π h·ª£p.</p>
                        </div>
                        """, unsafe_allow_html=True)
                    else:
                        st.markdown(f"""
                        <div class="normal-box">
                            <h2>üü¢ NORMAL - N·ªôi dung B√¨nh th∆∞·ªùng</h2>
                            <p style="font-size: 1.1rem;">Tin nh·∫Øn n√†y kh√¥ng c√≥ d·∫•u hi·ªáu n·ªôi dung ti√™u c·ª±c.</p>
                        </div>
                        """, unsafe_allow_html=True)
                    
                    # Metrics
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.metric(
                            "ƒê·ªô tin c·∫≠y",
                            f"{result['confidence']:.1%}",
                            delta=result['confidence_level']
                        )
                    
                    with col2:
                        st.metric(
                            "X√°c su·∫•t Toxic",
                            f"{result['toxic_probability']:.1%}"
                        )
                    
                    with col3:
                        st.metric(
                            "X√°c su·∫•t Normal",
                            f"{result['normal_probability']:.1%}"
                        )
                    
                    # Probability chart
                    st.subheader("üìä Ph√¢n b·ªë x√°c su·∫•t")
                    
                    fig = go.Figure(data=[
                        go.Bar(
                            x=['Normal', 'Toxic'],
                            y=[result['normal_probability'], result['toxic_probability']],
                            marker_color=['#4CAF50', '#F44336'],
                            text=[f"{result['normal_probability']:.1%}", 
                                  f"{result['toxic_probability']:.1%}"],
                            textposition='auto',
                        )
                    ])
                    
                    fig.update_layout(
                        title="X√°c su·∫•t d·ª± ƒëo√°n",
                        yaxis_title="X√°c su·∫•t",
                        yaxis=dict(range=[0, 1], tickformat='.0%'),
                        height=400,
                        showlegend=False
                    )
                    
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # Details expander
                    with st.expander("üîç Chi ti·∫øt ph√¢n t√≠ch"):
                        st.write("**VƒÉn b·∫£n g·ªëc:**")
                        st.code(result['original_text'])
                        
                        st.write("**VƒÉn b·∫£n ƒë√£ x·ª≠ l√Ω:**")
                        st.code(result['cleaned_text'])
                        
                        st.write("**Th√¥ng s·ªë k·ªπ thu·∫≠t:**")
                        st.json({
                            'Label': 'Toxic (1)' if result['is_toxic'] else 'Normal (0)',
                            'Confidence': f"{result['confidence']:.4f}",
                            'Confidence Level': result['confidence_level'],
                            'Toxic Probability': f"{result['toxic_probability']:.4f}",
                            'Normal Probability': f"{result['normal_probability']:.4f}"
                        })
        else:
            st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p n·ªôi dung tin nh·∫Øn!")

elif mode == "Ph√¢n t√≠ch h√†ng lo·∫°t":
    st.header("üìä Ph√¢n t√≠ch H√†ng lo·∫°t")
    
    st.info("Upload file CSV v·ªõi c·ªôt 'Content' ho·∫∑c 'text' ch·ª©a n·ªôi dung c·∫ßn ph√¢n t√≠ch")
    
    uploaded_file = st.file_uploader("Ch·ªçn file CSV", type=['csv'])
    
    if uploaded_file:
        try:
            df = pd.read_csv(uploaded_file)
            
            st.write("**Preview d·ªØ li·ªáu:**")
            st.dataframe(df.head())
            
            # Detect text column
            text_col = None
            for col in ['Content', 'content', 'text', 'Text', 'cleaned_content']:
                if col in df.columns:
                    text_col = col
                    break
            
            if text_col is None:
                st.error("‚ùå Kh√¥ng t√¨m th·∫•y c·ªôt ch·ª©a n·ªôi dung. Vui l√≤ng ƒë·∫£m b·∫£o c√≥ c·ªôt 'Content' ho·∫∑c 'text'")
            else:
                st.success(f"‚úì ƒê√£ ph√°t hi·ªán c·ªôt: '{text_col}'")
                
                if st.button("üöÄ B·∫Øt ƒë·∫ßu ph√¢n t√≠ch", use_container_width=True):
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    results = []
                    total = len(df)
                    
                    for idx, row in df.iterrows():
                        text = row[text_col]
                        result = predict_toxic(text, vectorizer, model)
                        
                        results.append({
                            'text': text[:100] + '...' if len(str(text)) > 100 else text,
                            'is_toxic': result['is_toxic'],
                            'label': result['label'],
                            'confidence': result['confidence'],
                            'toxic_probability': result['toxic_probability'],
                            'normal_probability': result['normal_probability']
                        })
                        
                        progress = (idx + 1) / total
                        progress_bar.progress(progress)
                        status_text.text(f"ƒê√£ x·ª≠ l√Ω: {idx + 1}/{total}")
                    
                    results_df = pd.DataFrame(results)
                    
                    # Statistics
                    st.markdown("---")
                    st.subheader("üìà Th·ªëng k√™ t·ªïng quan")
                    
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        st.metric("T·ªïng s·ªë", len(results_df))
                    
                    with col2:
                        toxic_count = results_df['is_toxic'].sum()
                        st.metric("Toxic", f"{toxic_count} ({toxic_count/len(results_df)*100:.1f}%)")
                    
                    with col3:
                        normal_count = len(results_df) - toxic_count
                        st.metric("Normal", f"{normal_count} ({normal_count/len(results_df)*100:.1f}%)")
                    
                    with col4:
                        avg_conf = results_df['confidence'].mean()
                        st.metric("ƒê·ªô tin c·∫≠y TB", f"{avg_conf:.1%}")
                    
                    # Charts
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        # Pie chart
                        fig = go.Figure(data=[go.Pie(
                            labels=['Normal', 'Toxic'],
                            values=[normal_count, toxic_count],
                            marker_colors=['#4CAF50', '#F44336']
                        )])
                        fig.update_layout(title="Ph√¢n b·ªë Toxic/Normal")
                        st.plotly_chart(fig, use_container_width=True)
                    
                    with col2:
                        # Confidence histogram
                        fig = go.Figure(data=[go.Histogram(
                            x=results_df['confidence'],
                            nbinsx=20,
                            marker_color='#1E88E5'
                        )])
                        fig.update_layout(
                            title="Ph√¢n b·ªë ƒë·ªô tin c·∫≠y",
                            xaxis_title="ƒê·ªô tin c·∫≠y",
                            yaxis_title="S·ªë l∆∞·ª£ng"
                        )
                        st.plotly_chart(fig, use_container_width=True)
                    
                    # Results table
                    st.subheader("üìã K·∫øt qu·∫£ chi ti·∫øt")
                    
                    # Filter
                    filter_option = st.selectbox(
                        "L·ªçc k·∫øt qu·∫£:",
                        ["T·∫•t c·∫£", "Ch·ªâ Toxic", "Ch·ªâ Normal"]
                    )
                    
                    if filter_option == "Ch·ªâ Toxic":
                        display_df = results_df[results_df['is_toxic'] == True]
                    elif filter_option == "Ch·ªâ Normal":
                        display_df = results_df[results_df['is_toxic'] == False]
                    else:
                        display_df = results_df
                    
                    st.dataframe(
                        display_df.style.applymap(
                            lambda x: 'background-color: #FFEBEE' if x == True else 'background-color: #E8F5E9',
                            subset=['is_toxic']
                        ),
                        use_container_width=True
                    )
                    
                    # Download
                    csv = results_df.to_csv(index=False).encode('utf-8')
                    st.download_button(
                        "üì• T·∫£i xu·ªëng k·∫øt qu·∫£ (CSV)",
                        csv,
                        "toxic_analysis_results.csv",
                        "text/csv",
                        use_container_width=True
                    )
                    
        except Exception as e:
            st.error(f"‚ùå L·ªói khi x·ª≠ l√Ω file: {e}")

else:  # History mode
    st.header("üìú L·ªãch s·ª≠ Ph√¢n t√≠ch")
    
    if len(st.session_state.history) == 0:
        st.info("Ch∆∞a c√≥ l·ªãch s·ª≠ ph√¢n t√≠ch. H√£y th·ª≠ ph√¢n t√≠ch m·ªôt s·ªë tin nh·∫Øn!")
    else:
        # Statistics
        toxic_count = sum(1 for item in st.session_state.history if item['is_toxic'])
        normal_count = len(st.session_state.history) - toxic_count
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("T·ªïng s·ªë ph√¢n t√≠ch", len(st.session_state.history))
        
        with col2:
            st.metric("Toxic", f"{toxic_count} ({toxic_count/len(st.session_state.history)*100:.0f}%)")
        
        with col3:
            st.metric("Normal", f"{normal_count} ({normal_count/len(st.session_state.history)*100:.0f}%)")
        
        st.markdown("---")
        
        # History table
        history_df = pd.DataFrame(st.session_state.history)
        history_df['timestamp'] = pd.to_datetime(history_df['timestamp'])
        history_df = history_df.sort_values('timestamp', ascending=False)
        
        st.dataframe(
            history_df.style.applymap(
                lambda x: 'background-color: #FFEBEE' if x == True else 'background-color: #E8F5E9',
                subset=['is_toxic']
            ),
            use_container_width=True
        )
        
        # Clear history
        if st.button("üóëÔ∏è X√≥a l·ªãch s·ª≠", use_container_width=True):
            st.session_state.history = []
            st.rerun()

# Footer
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #666; padding: 2rem;">
    <p>üõ°Ô∏è H·ªá th·ªëng Ph√°t hi·ªán B√¨nh lu·∫≠n Toxic</p>
    <p>Ph√°t tri·ªÉn v·ªõi ‚ù§Ô∏è s·ª≠ d·ª•ng Streamlit & XGBoost</p>
</div>
""", unsafe_allow_html=True)